{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPPE5J6397B68uOiGn50dTE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MK316/Workingpapers/blob/main/2025-insights/Recall25_stats.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recall 2nd analysis (0818~)"
      ],
      "metadata": {
        "id": "u3j_g2t7HAg-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "data from Drive > Research > Recall25>recalldata.csv"
      ],
      "metadata": {
        "id": "c3wAvO3LHGSe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vb7DvhV-Gt8w"
      },
      "outputs": [],
      "source": [
        "# --- Colab: Wilcoxon pre–post within Level=UG/GRAD ---\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import wilcoxon, norm\n",
        "\n",
        "# ---------- Load ----------\n",
        "csv_path = \"/content/recalldata.csv\"   # <-- change to your file\n",
        "df = pd.read_csv(csv_path)\n",
        "df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "# ---------- Cohort from Level ----------\n",
        "# Expecting Level already as UG / GRAD; also normalize common variants just in case.\n",
        "df[\"Cohort\"] = (\n",
        "    df[\"Level\"].astype(str).str.strip().str.upper()\n",
        "      .replace({\"UNDERGRAD\":\"UG\",\"UNDERGRADUATE\":\"UG\",\"U\":\"UG\",\n",
        "                \"GRADUATE\":\"GRAD\",\"G\":\"GRAD\"})\n",
        ")\n",
        "print(\"Cohort counts:\\n\", df[\"Cohort\"].value_counts(dropna=False))\n",
        "\n",
        "# ---------- Likert to numeric ----------\n",
        "likert = [\"Q1\",\"Q2\",\"Q3\",\"Q4\",\"Q5\",\"Q6\"]\n",
        "for c in likert:\n",
        "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "\n",
        "# ---------- Helpers ----------\n",
        "def iqr(s): return s.quantile(0.25), s.quantile(0.75)\n",
        "\n",
        "def rb_from_W(W, n_eff):\n",
        "    T = n_eff * (n_eff + 1) / 2.0\n",
        "    return (2*W/T) - 1.0\n",
        "\n",
        "def bootstrap_ci_rb(pre, post, n_boot=5000, seed=123):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    d_full = (post - pre)\n",
        "    mask = d_full != 0\n",
        "    pre, post = pre[mask], post[mask]\n",
        "    n = len(pre)\n",
        "    if n == 0:\n",
        "        return np.nan, np.nan\n",
        "    T = n * (n + 1) / 2.0\n",
        "    vals = np.empty(n_boot)\n",
        "    for b in range(n_boot):\n",
        "        idx = rng.integers(0, n, n)\n",
        "        d = post[idx] - pre[idx]\n",
        "        ranks = pd.Series(np.abs(d)).rank(method=\"average\").to_numpy()\n",
        "        W_plus  = ranks[d > 0].sum()\n",
        "        W_minus = ranks[d < 0].sum()\n",
        "        vals[b] = (W_plus - W_minus) / T\n",
        "    lo, hi = np.percentile(vals, [2.5, 97.5])\n",
        "    return float(lo), float(hi)\n",
        "\n",
        "def describe(x):\n",
        "    x = pd.Series(x).dropna()\n",
        "    if len(x)==0:\n",
        "        return dict(n=0, median=np.nan, q1=np.nan, q3=np.nan, mean=np.nan, sd=np.nan)\n",
        "    q1, q3 = x.quantile(0.25), x.quantile(0.75)\n",
        "    return dict(n=len(x), median=float(x.median()), q1=float(q1), q3=float(q3),\n",
        "                mean=float(x.mean()), sd=float(x.std(ddof=1)))\n",
        "\n",
        "def analyze_pair(df_cohort, pre_col, post_col, construct, cohort):\n",
        "    sub = df_cohort[[pre_col, post_col]].dropna().astype(float)\n",
        "    pre = sub[pre_col].to_numpy()\n",
        "    post = sub[post_col].to_numpy()\n",
        "\n",
        "    pre_d, post_d = describe(pre), describe(post)\n",
        "    if len(sub) == 0:\n",
        "        return {**{\"cohort\":cohort,\"construct\":construct},\n",
        "                **{k:np.nan for k in [\n",
        "                    \"pre_n\",\"pre_median\",\"pre_Q1\",\"pre_Q3\",\n",
        "                    \"post_n\",\"post_median\",\"post_Q1\",\"post_Q3\",\n",
        "                    \"W\",\"p_value\",\"r_rb\",\"r_rb_CI_lo\",\"r_rb_CI_hi\",\"r_from_Z\"\n",
        "                ]}}\n",
        "\n",
        "    # p-value (two-sided). Order as post, pre so “improvement” is post > pre\n",
        "    res = wilcoxon(post, pre, zero_method=\"wilcox\", alternative=\"two-sided\", method=\"auto\")\n",
        "    W = float(res.statistic); p = float(res.pvalue)\n",
        "\n",
        "    # Effect size from signed ranks\n",
        "    d = post - pre\n",
        "    mask = d != 0\n",
        "    d = d[mask]\n",
        "    n_eff = int(len(d))\n",
        "    if n_eff == 0:\n",
        "        r_rb = r_lo = r_hi = r_from_Z = np.nan\n",
        "    else:\n",
        "        ranks = pd.Series(np.abs(d)).rank(method=\"average\").to_numpy()\n",
        "        W_plus  = ranks[d > 0].sum()\n",
        "        W_minus = ranks[d < 0].sum()\n",
        "        T = n_eff * (n_eff + 1) / 2.0\n",
        "        r_rb = (W_plus - W_minus) / T                 # positive if post > pre\n",
        "        r_lo, r_hi = bootstrap_ci_rb(pre, post)       # same orientation\n",
        "        z_abs = norm.isf(p/2.0) if 0 < p < 1 else np.nan\n",
        "        r_from_Z = float(np.sign(r_rb) * z_abs / np.sqrt(n_eff)) if np.isfinite(z_abs) else np.nan\n",
        "\n",
        "    return {\n",
        "        \"cohort\": cohort, \"construct\": construct,\n",
        "        \"pre_n\": pre_d[\"n\"], \"pre_median\": pre_d[\"median\"], \"pre_Q1\": pre_d[\"q1\"], \"pre_Q3\": pre_d[\"q3\"],\n",
        "        \"post_n\": post_d[\"n\"], \"post_median\": post_d[\"median\"], \"post_Q1\": post_d[\"q1\"], \"post_Q3\": post_d[\"q3\"],\n",
        "        \"W\": W, \"p_value\": p, \"r_rb\": r_rb, \"r_rb_CI_lo\": r_lo, \"r_rb_CI_hi\": r_hi, \"r_from_Z\": r_from_Z\n",
        "    }\n",
        "\n",
        "# ---------- Run analyses ----------\n",
        "constructs = {\n",
        "    \"Digital confidence (DC)\": (\"Q1\", \"Q4\"),\n",
        "    \"Perceived teaching benefit (PTB)\": (\"Q2\", \"Q5\"),\n",
        "    \"Engagement & motivation (E&M)\": (\"Q3\", \"Q6\"),\n",
        "}\n",
        "\n",
        "rows = []\n",
        "for cohort in [\"UG\",\"GRAD\"]:\n",
        "    g = df[df[\"Cohort\"] == cohort]\n",
        "    for name, (pre_col, post_col) in constructs.items():\n",
        "        rows.append(analyze_pair(g, pre_col, post_col, name, cohort))\n",
        "\n",
        "summary = pd.DataFrame(rows)\n",
        "summary\n",
        "summary.to_csv(\"/content/survey_wilcoxon_summary.csv\", index=False)\n",
        "print(\"Saved to /content/survey_wilcoxon_summary.csv\")\n"
      ]
    }
  ]
}