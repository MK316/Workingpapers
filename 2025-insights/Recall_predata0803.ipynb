{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyO5MyjZXcWD+S+a7UegKa+v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MK316/Workingpapers/blob/main/2025-insights/Recall_predata0803.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recall predata analysis\n",
        "+ 2025. 7. 27"
      ],
      "metadata": {
        "id": "lR09Ba7jGtZz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "data: \"C:\\Users\\user\\iCloudDrive\\01_workingpapers\\00_2025-workingpapers\\2025c-DL-Kim&Lee\\analysis\\predata-analysis\\predata.csv\""
      ],
      "metadata": {
        "id": "JEmyQ662GjrP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| **Question #** | **Survey Question (Paraphrased)**                                                               | **Suggested Keyphrase**     |\n",
        "| -------------- | ----------------------------------------------------------------------------------------------- | --------------------------- |\n",
        "| **Q1\\_DB**     | Have you experienced or learned basic coding?                                                   | **Coding Exposure**         |\n",
        "| **Q2\\_DC**     | How would you rate your current digital literacy?                                               | **Digital Competence**      |\n",
        "| **Q3\\_CB**     | How beneficial do you think coding is for English teachers?                                     | **Coding Benefits**         |\n",
        "| **Q4\\_CA**     | If coding helps you create tailored materials, how willing are you to learn coding?             | **Coding Acceptance**       |\n",
        "| **Q5**         | List five keywords about coding for language educators‚Äîits benefits, challenges, and relevance. | **Coding-Related Keywords** |\n"
      ],
      "metadata": {
        "id": "c0lbNxaZGgeF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mu7nvUH_FxW4"
      },
      "outputs": [],
      "source": [
        "# üìå Step 1: Import libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# üìå Step 2: Upload your file (CSV or Excel)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# üìå Step 3: Load your file\n",
        "# Replace the file name below with your uploaded filename\n",
        "df = pd.read_csv(\"predata2.csv\")  # or .xlsx if applicable\n",
        "\n",
        "# üìå Step 4: Check column names and preview data\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üìå Step 5: Convert Likert scale columns to numeric if not already\n",
        "likert_cols = ['Q1_DB', 'Q2_DC', 'Q3_CB', 'Q4_CA']\n",
        "df[likert_cols] = df[likert_cols].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# üìå Step 6: Descriptive statistics by Group\n",
        "group_stats = df.groupby('Group')[likert_cols].agg(['mean', 'std', 'count']).round(2)\n",
        "display(group_stats)\n",
        "\n",
        "# üìå Step 7: Keyword frequency analysis from Q5\n",
        "from collections import Counter\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# Combine all Q5 responses by group\n",
        "for group_name, group_data in df.groupby('Level'):\n",
        "    print(f\"\\nüìù Keyword Summary for Group: {group_name}\")\n",
        "    text = \" \".join(group_data['Q5'].dropna().astype(str))\n",
        "    words = [word.strip().lower() for word in text.split()]\n",
        "    freq = Counter(words)\n",
        "    common = freq.most_common(20)\n",
        "    for word, count in common:\n",
        "        print(f\"{word}: {count}\")\n",
        "\n",
        "    # Optional: Generate word cloud\n",
        "    wordcloud = WordCloud(width=600, height=300, background_color='white').generate_from_frequencies(freq)\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis('off')\n",
        "    plt.title(f'WordCloud for {group_name}')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "WRhtwH53F424"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data to read\n",
        "\n",
        "df1 = pd.read_csv(\"02_combined.csv\")  # or .xlsx if applicable\n",
        "\n",
        "# üìå Step 4: Check column names and preview data\n",
        "print(\"Columns:\", df1.columns.tolist())\n",
        "df1.head()"
      ],
      "metadata": {
        "id": "cBvhQBvCrDhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text length"
      ],
      "metadata": {
        "id": "Zq9O1P8wqP3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Add a new column with text length\n",
        "# df1['Essay-E'] = df1['Essay-E'].astype(str).apply(len)\n",
        "\n",
        "# # Get descriptive statistics for text length\n",
        "# length_stats = df1['Essay-E'].describe()\n",
        "\n",
        "# print(length_stats)\n"
      ],
      "metadata": {
        "id": "G_ZZJRyoqSrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a new column with word count\n",
        "df1['Essay-E'] = df1['Essay-E'].astype(str)\n",
        "df1['word_count'] = df1['Essay-E'].apply(lambda x: len(x.split()))\n",
        "\n",
        "# Get descriptive statistics for word count\n",
        "length_stats = df1['word_count'].describe()\n",
        "\n",
        "print(length_stats)\n"
      ],
      "metadata": {
        "id": "Rz_a5-vWtkiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Descriptive statistics"
      ],
      "metadata": {
        "id": "9HJlpq5XHypG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# STEP 1: Load your CSV file\n",
        "# Replace with your filename if different\n",
        "df = pd.read_csv('/content/predata2.csv')  # Update this path if needed\n",
        "\n",
        "# STEP 2: Convert relevant columns to numeric\n",
        "cols_to_convert = ['Age', 'Q1_DB', 'Q2_DC', 'Q3_CB', 'Q4_CA']\n",
        "df[cols_to_convert] = df[cols_to_convert].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# STEP 3: Overall Descriptive Statistics\n",
        "print(\"‚úÖ Overall Summary Statistics:\\n\")\n",
        "print(f\"Number of Participants: {df['SID'].nunique()}\")\n",
        "print(f\"Mean Age: {df['Age'].mean():.2f} (SD = {df['Age'].std():.2f})\\n\")\n",
        "\n",
        "for col in ['Q1_DB', 'Q2_DC', 'Q3_CB', 'Q4_CA']:\n",
        "    print(f\"{col} - Mean: {df[col].mean():.2f}, SD: {df[col].std():.2f}\")\n",
        "\n",
        "# STEP 4: Descriptive Statistics by Level\n",
        "print(\"\\n‚úÖ Summary by Level:\\n\")\n",
        "grouped = df.groupby('Level').agg({\n",
        "    'SID': 'count',\n",
        "    'Age': ['mean', 'std'],\n",
        "    'Q1_DB': ['mean', 'std'],\n",
        "    'Q2_DC': ['mean', 'std'],\n",
        "    'Q3_CB': ['mean', 'std'],\n",
        "    'Q4_CA': ['mean', 'std']\n",
        "})\n",
        "\n",
        "# Clean column names for better readability\n",
        "grouped.columns = ['_'.join(col).strip() for col in grouped.columns.values]\n",
        "display(grouped.reset_index())\n"
      ],
      "metadata": {
        "id": "1pQ1IidzIF8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df['SID'])"
      ],
      "metadata": {
        "id": "EaTT8LNtUwUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparison by Level"
      ],
      "metadata": {
        "id": "buvEy4nWI4x6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normality of each group\n",
        "import pandas as pd\n",
        "from scipy.stats import shapiro\n",
        "\n",
        "# Load your data\n",
        "df = pd.read_csv('/content/predata2.csv')  # Replace with your file path\n",
        "\n",
        "# Columns of interest\n",
        "questions = ['Q2_DC', 'Q3_CB', 'Q4_CA']\n",
        "df[questions] = df[questions].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Drop rows with missing Level or question scores\n",
        "df = df.dropna(subset=['Level'] + questions)\n",
        "\n",
        "# Grouping\n",
        "levels = df['Level'].unique()\n",
        "\n",
        "print(\"‚úÖ Shapiro-Wilk Normality Test Results\\n\")\n",
        "\n",
        "for q in questions:\n",
        "    print(f\"--- {q} ---\")\n",
        "    for level in levels:\n",
        "        group_scores = df[df['Level'] == level][q]\n",
        "        stat, p = shapiro(group_scores)\n",
        "        print(f\"Level: {level} | W = {stat:.3f}, p = {p:.4f}\")\n",
        "        if p < 0.05:\n",
        "            print(\"  ‚ùó Not normally distributed\")\n",
        "        else:\n",
        "            print(\"  ‚úÖ Normally distributed\")\n",
        "    print()\n",
        "\n"
      ],
      "metadata": {
        "id": "j8SdYccWI7UT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Group comparison; using median\n",
        "‚úÖ Use Mann-Whitney U Test (for comparing two independent groups)"
      ],
      "metadata": {
        "id": "cYkebFtFJuZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import mannwhitneyu\n",
        "\n",
        "# Loop through each question\n",
        "questions = ['Q2_DC', 'Q3_CB', 'Q4_CA']\n",
        "levels = df['Level'].unique()\n",
        "\n",
        "# Assuming only two levels exist (e.g., 'UG' and 'Grad')\n",
        "level1 = levels[1]\n",
        "level2 = levels[2]\n",
        "\n",
        "print(\"‚úÖ Mann-Whitney U Test (Independent Samples)\\n\")\n",
        "\n",
        "for q in questions:\n",
        "    group1 = df[df['Level'] == level1][q].dropna()\n",
        "    group2 = df[df['Level'] == level2][q].dropna()\n",
        "\n",
        "    stat, p = mannwhitneyu(group1, group2, alternative='two-sided')\n",
        "\n",
        "    print(f\"{q}:\")\n",
        "    print(f\"  {level1} (n={len(group1)}), {level2} (n={len(group2)})\")\n",
        "    print(f\"  U = {stat:.2f}, p = {p:.4f}\")\n",
        "\n",
        "    if p < 0.05:\n",
        "        print(\"  ‚ùó Statistically significant difference between groups\")\n",
        "    else:\n",
        "        print(\"  ‚úÖ No significant difference between groups\")\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "MAZZaEETJzQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3 group comparison with median\n",
        "‚úÖ Kruskal-Wallis H Test for Q2‚ÄìQ4 by Level\n",
        "\n"
      ],
      "metadata": {
        "id": "5yLWvvOIKaLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import kruskal\n",
        "\n",
        "# Questions to analyze\n",
        "questions = ['Q2_DC', 'Q3_CB', 'Q4_CA']\n",
        "\n",
        "# Unique group labels (e.g., 'UG', 'GRAD', 'Control')\n",
        "group_labels = df['Level'].unique()\n",
        "\n",
        "print(\"‚úÖ Kruskal-Wallis H Test for Q2‚ÄìQ4 by Level\\n\")\n",
        "\n",
        "for q in questions:\n",
        "    print(f\"{q}:\")\n",
        "\n",
        "    # Collect values per group\n",
        "    group_data = [df[df['Level'] == group][q].dropna() for group in group_labels]\n",
        "\n",
        "    # Run Kruskal-Wallis test\n",
        "    stat, p = kruskal(*group_data)\n",
        "\n",
        "    print(f\"  H = {stat:.2f}, p = {p:.4f}\")\n",
        "\n",
        "    if p < 0.05:\n",
        "        print(\"  ‚ùó Statistically significant difference among groups\")\n",
        "    else:\n",
        "        print(\"  ‚úÖ No significant difference among groups\")\n",
        "\n",
        "    # Optional: print group sizes\n",
        "    for label, g in zip(group_labels, group_data):\n",
        "        print(f\"    {label}: n = {len(g)}, mean = {g.mean():.2f}\")\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "s0hHtR4DKdd7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}